# -*- coding: utf-8 -*-
"""HR ANALYSIS: CLUSTERING.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HuR_AcQNEPd-_mq_Z0Ue-xRRNL9zg9Bn

**HUMAN RESOURCE ANALYSIS**
"""

!pip install kneed

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from kneed import KneeLocator
from sklearn.metrics import silhouette_score, davies_bouldin_score

import warnings
warnings.filterwarnings("ignore")

data = pd.read_csv("/content/HR_Data_MNC_Data Science Lovers.csv")
data

data.drop ('Unnamed: 0', axis = 1, inplace = True)

data['Hire_Date'] = pd.to_datetime(data['Hire_Date'])

data.isnull().sum()

data.info()

data.describe()

"""# Exploratory Data Analysis"""

kolom_numerik = data.select_dtypes(include=['int64', 'float64'])

corr_matrix = kolom_numerik.corr()

plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Matriks Korelasi')
plt.show

import plotly.express as px
# Department-wise employee count
dept_counts = data['Department'].value_counts().reset_index()
dept_counts.columns = ['Department', 'Employee_Count']

print("Employee Count by Department")
print(dept_counts)

# bar chart
fig = px.bar(
    dept_counts,
    x='Department',
    y='Employee_Count',
    text='Employee_Count',
    title='Employee Count by Department',
    color='Department'
)

fig.update_traces(textposition='outside')
fig.update_layout(
    xaxis_title="Department",
    yaxis_title="Number of Employees",
    showlegend=False
)

fig.show()

avg_salary = data.groupby('Department')['Salary_INR'].mean().reset_index()
avg_salary.columns = ['Department', 'Average_Salary']

print("Average Salary per Department:")
print(avg_salary)

fig = px.bar(
    avg_salary,
    x="Department",
    y="Average_Salary",
    text='Average_Salary',
    title='Aaverage Salary per Department',
    color='Department'
)

fig.update_traces(texttemplate='₹%{text:,.0f}', textposition='outside')
fig.update_layout(
    xaxis_title="Department",
    yaxis_title="Average Salary (INR)",
    showlegend=False
)

fig.show()

workmode_counts = data['Work_Mode'].value_counts().reset_index()
workmode_counts.columns = ['Work_Mode', 'Employee_Count']

print("Work Mode Distribution of Employees:")
print(workmode_counts)

# pie chart
fig = px.pie(
    workmode_counts,
    names='Work_Mode',
    values='Employee_Count',
    title='Distribution of Employees by Work Mode',
    hole=0.4  # donut style
)

# Percentage labels
fig.update_traces(textinfo='percent+label')

fig.show()

status_counts = data['Status'].value_counts(normalize=True) * 100
status_counts = status_counts.reset_index()
status_counts.columns = ['Status', 'Percentage']

print("Active vs Resigned Employees (%):")
print(status_counts)

# pie chart
fig = px.pie(
    status_counts,
    names='Status',
    values='Percentage',
    title='Active vs Resigned Employees (%)',
    hole=0.3  # donut style
)

# Show percentage + label
fig.update_traces(textinfo='percent+label')

fig.show()

location_counts = data['Location'].value_counts().reset_index()
location_counts.columns = ['Location', 'Employee_Count']

# top location
top_location = location_counts.iloc[0]
print(f"Location with the highest number of employees: {top_location['Location']} ({top_location['Employee_Count']} employees)")

# Show top 10 locations in bar chart
fig = px.bar(
    location_counts.head(10),
    x='Location',
    y='Employee_Count',
    text='Employee_Count',
    title='Top 10 Locations with Most Employees',
    color='Location'
)

fig.update_traces(textposition='outside')
fig.update_layout(
    xaxis_title="Location (City, Country)",
    yaxis_title="Number of Employees",
    xaxis={'categoryorder':'total descending'},
    showlegend=False
)

fig.show()

resigned_df = data[data['Status'] == 'Resigned']

# Department-wise resigned employees
dept_resigned = resigned_df['Department'].value_counts().reset_index()
dept_resigned.columns = ['Department', 'Resigned_Count']

print("Department-wise Resigned Employees:")
print(dept_resigned)

fig1 = px.bar(
    dept_resigned,
    x='Department',
    y='Resigned_Count',
    text='Resigned_Count',
    title='Department-wise Resigned Employees',
    color='Department'
)
fig1.update_traces(textposition='outside')
fig1.update_layout(showlegend=False)
fig1.show()

attrition_data = data[data['Status'].isin(['Resigned', 'Terminated'])]

attrition_count = attrition_data['Job_Title'].value_counts()

top10_attrition = attrition_count.head(10)

plt.figure(figsize=(12, 8))
sns.barplot(x=top10_attrition.values, y=top10_attrition.index, palette='viridis')

plt.title('Top 10 Attrition by Job Title', fontsize=16, fontweight='bold')
plt.xlabel('Number of Employees', fontsize=12)
plt.ylabel('Job Title', fontsize=12)
plt.grid(axis='x', linestyle='--', alpha=0.7)

for index, value in enumerate(top10_attrition.values):
    plt.text(value, index, f'  {value}', va='center')

plt.tight_layout()
plt.show()

!pip install squarify
import squarify
sizes = top10_attrition.values.tolist()
labels = [f'{title}\n({count})' for title, count in top10_attrition.items()]
cmap = plt.get_cmap('viridis')
colors = [cmap(i / (len(sizes) - 1)) for i in range(len(sizes))]

plt.figure(figsize=(14, 10))
squarify.plot(
    sizes=sizes,
    label=labels,
    color=colors,
    alpha=0.8,
    pad=True
)
plt.title('Attrition by Job Title', fontsize=20, fontweight='bold')
plt.axis('off')
plt.show()

"""# Clustering"""

clustering_data = data.select_dtypes(include=['int64', 'float64'])
clustering_data['Salary_INR'].fillna(clustering_data['Salary_INR'].median(), inplace=True)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(clustering_data)

kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
data['Cluster'] = kmeans.fit_predict(X_scaled)

print("Number of employees in each cluster:")
print(data['Cluster'].value_counts())

cluster_profiles = data.groupby('Cluster')[['Salary_INR', 'Experience_Years', 'Performance_Rating']].mean()
print(cluster_profiles)

"""Berdasarkan nilai rata-rata yang telah dibuat, kita bisa memberikan makna pada setiap klaster:

**Klaster 0: Karyawan Berpengalaman & Bergaji Tinggi**
  - Karakteristik: Ini adalah kelompok dengan gaji tertinggi (rata-rata ₹1,69 juta) dan pengalaman paling tinggi (rata-rata 4,96 tahun). Rating kinerja mereka berada di level rata-rata (3.02).
  - Temuan: Kelompok ini kemungkinan besar terdiri dari para spesialis senior dan talenta kunci di perusahaan. Mereka adalah pilar dari organisasi, dan mempertahankan mereka harus menjadi prioritas utama.

**Klaster 1: Karyawan Berkinerja Rendah & Berpengalaman Sedang**

- Karakteristik: Kelompok ini memiliki gaji terendah (rata-rata ₹780 ribu) dan rating kinerja terburuk (1.74). Pengalaman mereka berada di tengah (rata-rata 5,66 tahun), yang menunjukkan bahwa mereka bukan karyawan baru.

- Temuan: Klaster ini bisa menjadi "talenta yang berisiko" atau "talenta yang underperform". Meskipun mereka memiliki pengalaman, kinerja mereka di bawah standar. Mereka mungkin tidak puas dengan kompensasi atau tidak memiliki keterampilan yang relevan.

**Klaster 2: Karyawan Berkinerja Tinggi & Gaji Standar**

- Karakteristik: Kelompok ini memiliki rating kinerja tertinggi (4.17) tetapi gaji rata-rata yang mirip dengan Klaster 1 (rata-rata ₹777 ribu). Pengalaman mereka paling sedikit (rata-rata 4,42 tahun).

- Temuan: Klaster ini kemungkinan besar adalah "bintang baru" yang sangat produktif tetapi mungkin merasa kompensasinya belum setara dengan kontribusi mereka. Mereka adalah kelompok yang berisiko tinggi untuk mengalami attrition jika tidak diperhatikan.

"""

data_jitter = data.copy()
data_jitter['Experience_Years_Jittered'] = data_jitter['Experience_Years'] + np.random.uniform(-0.2, 0.2, size=len(data_jitter))

plt.figure(figsize=(10, 8))
sns.scatterplot(
    x='Experience_Years',
    y='Salary_INR',
    hue='Cluster',
    data=data_jitter,
    palette='viridis',
    s=100
)
plt.title('Klaster Karyawan Berdasarkan Pengalaman dan Gaji')
plt.show()

numeric_columns = [
    'Salary_INR', 'Experience_Years', 'Performance_Rating'
]


sns.set(style= "white")
pair_plot = sns.pairplot(
    data[numeric_columns + ['Cluster']],
    hue="Cluster",
    palette="Dark2",
    diag_kind="kde",
    markers=["o", "s", "D"],
    height=3
)

plt.show()

data.head()

numeric_columns = data.select_dtypes(include=['int64', 'float64']).columns

cluster_analysis = data.groupby('Cluster')[numeric_columns].agg(['mean','min','max']).T

cluster_analysis